<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Saurabh Joshi</title><link>https://sbjoshi.github.io/</link><atom:link href="https://sbjoshi.github.io/index.xml" rel="self" type="application/rss+xml"/><description>Saurabh Joshi</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 12 Jan 2024 00:00:00 +0000</lastBuildDate><image><url>https://sbjoshi.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Saurabh Joshi</title><link>https://sbjoshi.github.io/</link></image><item><title>GPURepair: Automated Repair of GPU Kernels (Extended Version)</title><link>https://sbjoshi.github.io/publication/gpurepair-sadhana24/</link><pubDate>Fri, 12 Jan 2024 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/gpurepair-sadhana24/</guid><description/></item><item><title>DORA: Distributed Agreement with Simple Majority</title><link>https://sbjoshi.github.io/publication/dora-icdcs2023/</link><pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/dora-icdcs2023/</guid><description/></item><item><title>DORA</title><link>https://sbjoshi.github.io/project/dora/</link><pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/project/dora/</guid><description>&lt;h2 id="dora">DORA&lt;/h2>
&lt;p>DORA is a scaleable, transparent and efficient distributed oracle agreement protocole designed and developed at SupraOracles. Find more details &lt;a href="https://supra.com/news/dora-distributed-oracle-agreement" target="_blank" rel="noopener">here&lt;/a>&lt;/p></description></item><item><title>OpenMP aware MHP Analysis for Improved Static Data-Race Detection</title><link>https://sbjoshi.github.io/publication/llov-mhp-llvmhpc21/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/llov-mhp-llvmhpc21/</guid><description/></item><item><title>Anomaly Detection in Data Plane Systems using Packet Execution Paths</title><link>https://sbjoshi.github.io/publication/spin2021-anomaly-detection/</link><pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/spin2021-anomaly-detection/</guid><description/></item><item><title>GPURepair: Automated Repair of GPU Kernels</title><link>https://sbjoshi.github.io/publication/gpurepair-vmcai21/</link><pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/gpurepair-vmcai21/</guid><description/></item><item><title>LLOV: A Fast Static Data-Race Checker for OpenMP Programs</title><link>https://sbjoshi.github.io/publication/llov-taco20/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/llov-taco20/</guid><description/></item><item><title>On the tractability of $(k,i)$-coloring (Extended Journal Version)</title><link>https://sbjoshi.github.io/publication/kicoloring/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/kicoloring/</guid><description/></item><item><title>Reflections on "Incremental Cardinality Constraints for MaxSAT"</title><link>https://sbjoshi.github.io/publication/reflections-virtualvolume-cp19/</link><pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/reflections-virtualvolume-cp19/</guid><description/></item><item><title>Open-WBO-Inc: Approximation Strategies for Incomplete Weighted MaxSAT</title><link>https://sbjoshi.github.io/publication/open-wbo-inc-jsat/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/open-wbo-inc-jsat/</guid><description/></item><item><title>Phase Transition Behavior of Cardinality and XOR Constraints</title><link>https://sbjoshi.github.io/publication/phasetransition-ijcai19/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/phasetransition-ijcai19/</guid><description/></item><item><title>Pinaka: Symbolic Execution Meets Incremental Solving - (Competition Contribution)</title><link>https://sbjoshi.github.io/publication/pinaka-tacas19/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/pinaka-tacas19/</guid><description/></item><item><title>LLOV</title><link>https://sbjoshi.github.io/project/llov/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/project/llov/</guid><description/></item><item><title>Approximation Strategies for Incomplete MaxSAT</title><link>https://sbjoshi.github.io/publication/open-wbo-inc-cp18/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/open-wbo-inc-cp18/</guid><description/></item><item><title>Open-WBO-Inc</title><link>https://sbjoshi.github.io/project/openwboinc/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/project/openwboinc/</guid><description>&lt;h2 id="open-wbo-inc">Open-WBO-Inc&lt;/h2>
&lt;p>Open-WBO-Inc is an open-source incomplete solver for MaxSAT. Often, real-world applications demand a &lt;em>good&lt;/em> answer to MaxSAT optimization problem very quickly. Incomplete solvers strive to find a &lt;em>good&lt;/em> answer very fast but may not guarantee &lt;em>optimality&lt;/em> of the provided answer.&lt;/p>
&lt;p>Open-WBO-Inc has won several accolades at international arena. In addition, it serves as a platform on top of which other award winning solvers such as &lt;a href="https://github.com/jezberg/loandra" target="_blank" rel="noopener">Loandra&lt;/a> and TT-Open-WBO-Inc has been built.&lt;/p>
&lt;ul>
&lt;li>MaxSAT Evaluation 2019: 2 Bronze&lt;/li>
&lt;li>MaxSAT Evaluation 2018: 1 Gold, 1 Silver&lt;/li>
&lt;/ul></description></item><item><title>On the tractability of $(k,i)$-coloring</title><link>https://sbjoshi.github.io/publication/kicoloring-caldam18/</link><pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/kicoloring-caldam18/</guid><description/></item><item><title>GPURepair</title><link>https://sbjoshi.github.io/project/gpurepair/</link><pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/project/gpurepair/</guid><description>&lt;h2 id="gpurepair">GPURepair&lt;/h2>
&lt;p>GPURepair is a tool that can propose a fix to data-race and barrier-divergence errors in CUDA and OpenCL kernels. It uses &lt;a href="https://github.com/mc-imperial/gpuverify" target="_blank" rel="noopener">GPUVerify&lt;/a> as an oracle. It can also propose a fix for inter-block data-race in CUDA kernels using &lt;em>CUDA Cooperative Groups&lt;/em>.&lt;/p></description></item><item><title>OpenWBO</title><link>https://sbjoshi.github.io/project/openwbo/</link><pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/project/openwbo/</guid><description>&lt;h2 id="openwbo">OpenWBO&lt;/h2>
&lt;p>OpenWBO is a modular open-source sover for MaxSAT and Pseudo-Boolean formulas. OpenWBO has won several accolades in various international arena.&lt;/p>
&lt;ul>
&lt;li>MaxSAT Evaluation 2017: 2 Gold, 1 Silver&lt;/li>
&lt;li>MaxSAT Evaluation 2016: 1 Gold, 1 Silver&lt;/li>
&lt;li>Pseudo-Boolean Evaluation 2016: 2 Silver, 2 Bronze&lt;/li>
&lt;li>MaxSAT Evaluation 2015 : 1 Gold, 1 Silver&lt;/li>
&lt;li>MaxSAT FLoC Olympic Games 2014 : 2 Gold&lt;/li>
&lt;li>MaxSAT Evaluation 2014 : 1 Gold, 1 Silver&lt;/li>
&lt;/ul></description></item><item><title>Pinaka</title><link>https://sbjoshi.github.io/project/pinaka/</link><pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/project/pinaka/</guid><description>&lt;h2 id="pinaka-symbolic-execution-meets-incremental-solving">Pinaka: Symbolic Execution meets Incremental Solving&lt;/h2>
&lt;p>Symbolic execution as well as incremental solving has been quite well known concepts to the researchers and students working in the field of Formal Methods.&lt;/p>
&lt;p>Today I am going to write about &lt;a href="https://github.com/sbjoshi/Pinaka" target="_blank" rel="noopener">Pinaka&lt;/a>, a symbolic execution engine that combines symbolic execution with incremental solving in a fairly simple fashion.&lt;/p>
&lt;p>If you are merely looking at documentation about how to use it, please refer to the post on &lt;a href="https://sbjoshi.github.io/post/pinaka-usermanual">&lt;em>&amp;ldquo;How to use Pinaka&amp;rdquo;&lt;/em>&lt;/a>.&lt;/p>
&lt;h4 id="incremental-solving">Incremental Solving&lt;/h4>
&lt;p>Many modern day constraint solvers, such as SAT and SMT solvers support incremental solving in some fashion.
Say, for some problem, we require solutions for the following set of formulas: $\varphi, \varphi \wedge \Delta_1, \varphi \wedge \Delta_1 \wedge \Delta_2$&lt;/p>
&lt;p>One of the ways to solve these is to create a solver instance for each of these formulas separately and ask the solver for a solution for each of these separately. Note however, that any assignment/model/interpretation that does not satisfy $\varphi$ is not going to satisfy the other two. Similarly, any assignment that does not satisfy $\varphi\wedge\Delta_1$ is not going to satisfy the last formula. Essentially, adding more constraints to the existing formula is going to preserve the fact that assignments that &lt;em>falsifies&lt;/em> a formula continue to do so even after more constraints are added.&lt;/p>
&lt;p>It would result in a huge performance gain, if we use the same solver instance to solve all the three formulas. When we reuse the solver instance, the internal state of the solver including variable and clause activity scores, learned clauses, etc., are carried over and reused for the next query.&lt;/p>
&lt;p>This way of solving a set of formulas with successive queries to the same solver will be denoted as &lt;em>partial incremental mode&lt;/em>.&lt;/p>
&lt;p>Now, suppose we have the following set of formulas: $\varphi \wedge \Delta_1, \varphi \wedge \Delta_2, \varphi \wedge \Delta_3$. Note that, though $\varphi$ remains common, it is no longer the case that one formula is just addition of constraints over the other. The second formula can be obtained from the first by &lt;em>deleting&lt;/em> $\Delta_1$ and adding $\Delta_2$. However, the moment you delete a set of constraints, the assignment that used to falsify the old formula may no longer falsify the new formula. Therefore, the search space that was discarded earlier by the solver has to be explored again. The internal state of the solver can not easily be reused in such a scenario.&lt;/p>
&lt;p>However, many modern day solvers have another trick up their sleeve, called &lt;em>assumptions&lt;/em>. Assumptions are a list of literals that can be logically thought of as added unit clauses. When you know that some constraint may no longer be required for successive queries, you can add that constraint being enforced by an assumption. Therefore, the first formula, can be rewritten as $\varphi \wedge (b_1 \implies \Delta_1) \wedge [b_1]$. Here, $[b_1]$ is an assumption, which can logically be thought as a unit clause. Therefore, making this formula &lt;em>equisatisfiable&lt;/em> to $\varphi \wedge \Delta_1$. To transform, the first formula to the second one, now we can add $(b_2\implies \Delta_2)$ and change the set of assumptions to $[\neg b_1,b_2]$. So the second formula now looks like:&lt;/p>
&lt;p>$$\varphi \wedge (b_1\implies \Delta_1) \wedge (b2\implies \Delta_2) \wedge [\neg b_1,b_2]$$.&lt;/p>
&lt;p>When you think that assumptions are logically just unit clauses, then the above formula in some sense &lt;em>deletes&lt;/em> $\Delta_1$ because the premise of the implicant is &lt;em>false&lt;/em>. Therefore, we are transforming one formula to the next just by adding $(b_i \implies \Delta_i)$ and changing assumptions. Note that we are changing $[b_1]$ to $[\neg b_1]$, which looks like we are &lt;em>deleting&lt;/em> $b_1$ and adding $\neg b_1$, but solvers treat assumptions in a spacial manner internally. It is still the case that the assignment that &lt;em>falsifies&lt;/em> the first formula may no longer falsify the second formula. However, using assumptions still allow a lot of information pertaining to $\varphi$ to be carried over to the next query. Thus, assumptions allow us to salvage at least some information, which would be lost if we were to create a different solver instance for each query.&lt;/p>
&lt;p>Of course, adding such $(b_i \implies \Delta_i)$ for a lot of successive queries result in degradation of performance because of large memory footprint and slower iteration over internal data-structures. However, assumptions allows us to reuse a solver instance and can give great performance benefits if the common subformula $\varphi$ is very large and $\Delta_i$ are small and few in numbers.&lt;/p>
&lt;p>This way of using the same solver instance for successive queries will be denoted as &lt;em>full incremental mode&lt;/em>.&lt;/p>
&lt;h4 id="symbolic-execution">Symbolic Execution&lt;/h4>
&lt;p>Let&amp;rsquo;s take a look at a motivating example for symbolic execution.&lt;/p>
&lt;p>Look at the subroutine &lt;code>foo&lt;/code> given below. Note that the &lt;em>assertion violation&lt;/em> will happen only when variable &lt;code>y&lt;/code> gets &lt;code>-10&lt;/code> as its value at &lt;code>line 1&lt;/code>. Assuming an &lt;code>int&lt;/code> to be of &lt;code>32&lt;/code> bits, and if you were to test this subroutine by generating values of &lt;code>y&lt;/code> uniformly randomly and running &lt;code>foo&lt;/code>, then the probability of you finding the bug will be $2^{-32}$.&lt;/p>
&lt;pre>&lt;code class="language-c">1 void foo(int y) {
2 int x=10;
3 x=x+y;
4 if(x==0) {
5 x=x+1;
6 if(y&amp;lt;-10)
7 x=x-1;
8 }
9 else {
10 x=0;
11 }
12 assert(x==0);
13 }
&lt;/code>&lt;/pre>
&lt;p>The problem with testing, as mentioned above, is that a single run only exposes program behaviour for a single input value along a single path.&lt;/p>
&lt;p>In symbolic execution, it is possible to explore program behaviour for a set of input values along a single path. We will not talk about multi-path symbolic execution in this post.&lt;/p>
&lt;p>Symbolic execution uses a predicate at every program point along a path to represent the set of values program variables can take along the given path. This predicate is also often called a &lt;em>symbolic state&lt;/em>.&lt;/p>
&lt;p>For example, the symbolic state after &lt;em>executing&lt;/em> lines &lt;code>1-3&lt;/code> would be :&lt;/p>
&lt;p>$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0 \quad (1) $$&lt;/p>
&lt;p>Here, $x_0,x_1,y_0$ are symbolic /mathematical variables that represent the set of values that the corresponding program variable can take at corresponding program points. For example, $(x_0,10), (x_1,11),(y_0,3)$ as a program state is not possible after executing line &lt;code>3&lt;/code> as it does not satisfy the predicate mentioned above. On the other hand $(x_0,10),(x_1,12),(y_0,2)$ satisfies the predicate, indicating that after executing lines &lt;code>1-3&lt;/code> program variable &lt;code>x&lt;/code> can be &lt;code>12&lt;/code> and &lt;code>y&lt;/code> can be &lt;code>2&lt;/code>. Similarly, $(x_0,10),(x_1,0),(y_0,-10)$ is also a solution to the predicate indicating that &lt;code>x&lt;/code> taking the value &lt;code>0&lt;/code> and &lt;code>y&lt;/code> taking the value &lt;code>-10&lt;/code> at line &lt;code>4&lt;/code> is a possibility.&lt;/p>
&lt;p>Line &lt;code>4&lt;/code> is a branch and gives rise to two symbolic states.
Symbolic state for the &lt;em>then&lt;/em> branch is:
$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0\wedge x_1=0\quad(2)$$&lt;/p>
&lt;p>The symbolic state for the &lt;em>else&lt;/em> branch is:
$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0\wedge x_1\neq0\quad(3)$$.&lt;/p>
&lt;p>&lt;em>Pinaka&lt;/em> being a single path execution engine, maintains a worklist of symbolic states that are yet to be explored further. Therefore, at a branch, it picks one state to be explored further and puts the other one on the worklist. Say, it picked the symbolic state for the &lt;em>then&lt;/em> branch. &lt;em>Pinaka&lt;/em> also employs &lt;em>eager feasibility checks&lt;/em>. In other words, at every branch, it poses a query to a constraint solver whether the symbolic state is &lt;em>feasible&lt;/em> or not. If there is no solution to the predicate, then the corresponding symbolic state is deemed to be &lt;em>infeasible&lt;/em>, indicating that in an actual/concrete execution, it is not possible for the control to reach this point.&lt;/p>
&lt;p>In our example, &lt;em>then&lt;/em> branch at line &lt;code>4&lt;/code> is feasible. Symbolic state for the &lt;em>then&lt;/em> branch at line &lt;code>6&lt;/code>would be:&lt;/p>
&lt;p>$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0\wedge x_1=0 \ \wedge x_2=x_1+1 \wedge y_0&amp;lt;-10 \quad(4) $$&lt;/p>
&lt;p>Symblic state for (implicit) &lt;code>else&lt;/code> at line &lt;code>8&lt;/code> would be:
$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0\wedge x_1=0 \ \wedge x_2=x_1+1 \wedge y_0\geq -10 \quad(5) $$&lt;/p>
&lt;p>&lt;em>Pinaka&lt;/em> uses incremental solving aggressively. Note that the symbolic state for &lt;em>then&lt;/em> branch at line &lt;code>4&lt;/code> is of the form $\varphi$ and the symbolic state for the &lt;em>then&lt;/em> branch at line &lt;code>6&lt;/code> differs by two additional constraint $x_2=x_1+1 \wedge y_0&amp;lt;-10$ which can be considered as $\Delta_1$ as mentioned in earlier section. Therefore, along a single path, &lt;em>Pinaka&lt;/em> continues to reuse the same solver instance as long as the symbolic state remains feasible.&lt;/p>
&lt;p>Observe that this symbolic state given in $(4)$ above is infeasible and therefore, in a real execution line &lt;code>7&lt;/code> is unreachable irrespective of the input value of &lt;code>y&lt;/code>.&lt;/p>
&lt;p>In the &lt;em>DFS (depth first search)&lt;/em> exploration strategy, &lt;em>Pinaka&lt;/em> picks the last unexplored symbolic state from the list. This can easily be achieved when we operate the worklist of symbolic states pending further exploration in a LIFO (Last In First Out) manner. In this example, it would pick the symbolic state mentioned at (5) above, corresponding to the if condition being &lt;em>false&lt;/em> at line &lt;code>6&lt;/code>.&lt;/p>
&lt;p>In the &lt;em>partial-incremental&lt;/em> mode, once a symbolic state is found to be infeasible, a new solver instance is created to explore the yet unexplored symbolic state, in this case, (5) above.&lt;/p>
&lt;p>In the &lt;em>full incremental mode&lt;/em>, the predicate/formula at line &lt;code>6&lt;/code> would have looked like the following:
$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0 \ \wedge (b_1 \implies x_1=0) \wedge (b_1 \implies x_2=x_1+1) \ \wedge (b_1 \implies (b_2 \implies y_0&amp;lt;-10)) \wedge [b_1,b_2] \quad(6) $$&lt;/p>
&lt;p>Notice that a new assumption is added for every branch condition as later we may want to &lt;em>backtrack&lt;/em> from a &lt;em>then&lt;/em> branch and explore an &lt;em>else&lt;/em> branch. So in the full incremental mode, the same solver instance will be reused after the symbolic state at line &lt;code>6&lt;/code> for the &lt;em>then&lt;/em> branch is found to be infeasible. For the &lt;em>else&lt;/em> branch, the formula would look like the following:
$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0 \ \wedge (b_1 \implies x_1=0) \wedge (b_1 \implies x_2=x_1+1) \ \wedge (b_1 \implies (b_2 \implies y_0&amp;lt;-10)) \
\wedge (b_1 \implies (\neg b_2 \implies y\geq -10))
\wedge [b_1,\neg b_2] \quad(7) $$&lt;/p>
&lt;p>Once the symbolic execution has gone through the path depicted by lines &lt;code>1-6, 8,11&lt;/code> we have to check for assertion violation. Essentially, we again want to know, if there is any set of values that program variables can take that can result in assertion violation. This can be done by asking if the following symbolic state is feasible:&lt;/p>
&lt;p>$$y_0 \wedge x_0 = 10 \wedge x_1 = x_0 + y_0\wedge x_1=0 \ \wedge x_2=x_1+1 \wedge y_0\geq -10 \wedge x_2\neq 0 \quad(8) $$&lt;/p>
&lt;p>Observe that we negated the condition inside the assertion as we want to know if the program variables can take a set of values that violates (negates) the condition given in the assertion. Note that (8) above is satisfiable with $(y_0,-10)$, thus revealing that &lt;code>foo&lt;/code> can fail if the value of the parameter &lt;code>y&lt;/code> is &lt;code>-10&lt;/code>.&lt;/p>
&lt;p>Number of paths in a program can grow exponentially in proportion to the number of branches in the program. This path explosion problem can pose quite a problem for single-path symbolic execution engines such as &lt;em>Pinaka&lt;/em>. Eager infeasibility checks employed by &lt;em>Pinaka&lt;/em> gives it tremendous performance boost as all the paths beyond an infeasible symbolic state is discarded. However, doing eager infeasibility checks would mean that every time a branch is encountered, a solver query has to be fired. Since querying a solver is expensive, increasing the number of queries can pose another challenge. That is when integration of incremental solving can provide tremendous benefit.&lt;/p>
&lt;h4 id="termination">Termination&lt;/h4>
&lt;p>Loops and recursions are primary programming constructs in a programming language that causes non-termination in a program.&lt;/p>
&lt;p>&lt;em>Pinaka&lt;/em> performs loop-unrolling and function in-lining lazily and on-demand. This feature allows it to be used to check for termination in some cases.&lt;/p>
&lt;p>Let&amp;rsquo;s take a look at the following program fragment:&lt;/p>
&lt;pre>&lt;code class="language-c">1 while(x &amp;lt; 10) {
2 y = y + 1;
3 if(y &amp;lt; 5) {
4 x = x + 1
5 }
6 }
&lt;/code>&lt;/pre>
&lt;p>Note that for all the values of &lt;code>x&lt;/code> and &lt;code>y&lt;/code>, if they satisfy $x-y&amp;gt;5 \vee x\geq 10$, this loop will terminate. It may not terminate otherwise. However, &lt;em>Pinaka&lt;/em> does not compute this relation. Instead, it treats the loop condition just as a branch. So the loop will keep being unrolled on-demand as long as the symbolic state at line &lt;code>1&lt;/code> continues to remain feasible. In another words, if there is any set of values for &lt;code>x&lt;/code> and &lt;code>y&lt;/code> which would make it possible for the loop to iterate at least one more time, &lt;em>Pinaka&lt;/em> will also go around the loop symbolically executing the loop at least one more time. As a consequence, for a program which does not violate any assertions (safe programs), &lt;em>Pinaka&lt;/em> will terminate only if the program itself is terminating. Of course, we are assuming that the solver queries themselves terminate and &lt;em>Pinaka&lt;/em> does not run out of memory and time.&lt;/p>
&lt;p>For programs, that may violate assertions, this guarantee does not hold. Since if &lt;em>Pinaka&lt;/em> finds an assertion violation along some path, it will terminate even if there exist paths in the programs which are non-terminating.&lt;/p>
&lt;h4 id="do-it-yourself">Do it yourself&lt;/h4>
&lt;p>Those who want to try this example out and compare testing against symbolic execution, following is the C++ program for testing:&lt;/p>
&lt;pre>&lt;code class="language-cpp">#include&amp;lt;random&amp;gt;
#include&amp;lt;limits&amp;gt;
#include&amp;lt;iostream&amp;gt;
#include&amp;lt;cassert&amp;gt;
void foo(int y) {
int x=10;
x=x+y;
if(x==0) {
x=x+1;
if(y&amp;lt;-10)
x=x-1;
}
else {
x=0;
}
assert(x==0);
}
int main()
{
std::random_device rseed;
std::mt19937 rng(rseed());
std::uniform_int_distribution&amp;lt;int&amp;gt; dist(std::numeric_limits&amp;lt;int&amp;gt;::min(),std::numeric_limits&amp;lt;int&amp;gt;::max());
unsigned i=0;
unsigned max=1000000;
//unsigned max=std::numeric_limits&amp;lt;unsigned&amp;gt;::max();
while(i&amp;lt;max)
{
std::cout&amp;lt;&amp;lt; &amp;quot;i : &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; std::endl;
foo(dist(rng));
i++;
};
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>Compile, run and observe using the following commands:&lt;/p>
&lt;pre>&lt;code>$ g++ -o footest filename.cpp
$ ./footest 2&amp;gt;&amp;amp;1 &amp;gt; foorun.log
$ tail foorun.log
&lt;/code>&lt;/pre>
&lt;p>I could not trigger the assertion violation when I tried. In contrast when you run &lt;em>Pinaka&lt;/em> using the following command you will get assertion violation notification in a fraction of a second.&lt;/p>
&lt;pre>&lt;code>$ pinaka --function foo filename.c
&lt;/code>&lt;/pre>
&lt;h4 id="references">References&lt;/h4>
&lt;ul>
&lt;li>&lt;em>Pinaka&lt;/em> binaries are available &lt;a href="https://github.com/sbjoshi/Pinaka" target="_blank" rel="noopener">here&lt;/a>. Pinaka performed reasonably well and quite fast in &lt;a href="https://sv-comp.sosy-lab.org/2019/results/results-verified/" target="_blank" rel="noopener">SVCOMP 2019&lt;/a> and &lt;a href="https://sv-comp.sosy-lab.org/2020/results/results-verified/" target="_blank" rel="noopener">SVCOMP 2020&lt;/a>&lt;/li>
&lt;li>You may also refer to the following paper: Eti Chaudhary and Saurabh Joshi, &amp;ldquo;&lt;a href="https://link.springer.com/chapter/10.1007/978-3-030-17502-3_20" target="_blank" rel="noopener">Pinaka: Symbolic Execution meets Incremental Solving&lt;/a>&amp;rdquo;, TOOLympics, TACAS (3), LNCS Vol. 11529, pp. 234&amp;ndash;238, 2019. Pre-print version is available on &lt;a href="https://arxiv.org/pdf/1903.02309.pdf" target="_blank" rel="noopener">arXiv&lt;/a>.&lt;/li>
&lt;/ul></description></item><item><title>Precise Predictive Analysis for Discovering Communication Deadlocks in MPI Programs</title><link>https://sbjoshi.github.io/publication/predictiveanalysis-toplas/</link><pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/predictiveanalysis-toplas/</guid><description/></item><item><title>Equivalence Checking of a Floating-Point Unit Against a High-Level C Model</title><link>https://sbjoshi.github.io/publication/equivalencefpu-fm16/</link><pubDate>Fri, 01 Jul 2016 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/equivalencefpu-fm16/</guid><description/></item><item><title>The virtues of conflict: analysing modern concurrency</title><link>https://sbjoshi.github.io/publication/concurrency-ppoppp16/</link><pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/concurrency-ppoppp16/</guid><description/></item><item><title>On Using Incremental Encodings in Unsatisfiability-based MaxSAT Solving</title><link>https://sbjoshi.github.io/publication/inc-cardinality-jsat14/</link><pubDate>Sun, 01 Nov 2015 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/inc-cardinality-jsat14/</guid><description/></item><item><title>Generalized Totalizer Encoding for Pseudo-Boolean Constraints</title><link>https://sbjoshi.github.io/publication/gte-cp15/</link><pubDate>Wed, 01 Jul 2015 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/gte-cp15/</guid><description/></item><item><title>Safety Verification and Refutation by $k$-Invariants and $k$-Induction</title><link>https://sbjoshi.github.io/publication/kiki-sas15/</link><pubDate>Wed, 01 Jul 2015 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/kiki-sas15/</guid><description/></item><item><title>Property-Driven Fence Insertion Using Reorder Bounded Model Checking</title><link>https://sbjoshi.github.io/publication/robmc-fm15/</link><pubDate>Mon, 01 Jun 2015 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/robmc-fm15/</guid><description/></item><item><title>Incremental Cardinality Constraints for MaxSAT</title><link>https://sbjoshi.github.io/publication/inc-cardinality-cp14/</link><pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/inc-cardinality-cp14/</guid><description/></item><item><title>Automatically finding atomic regions for fixing bugs in Concurrent Programs</title><link>https://sbjoshi.github.io/publication/atomicinf-arxiv/</link><pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/atomicinf-arxiv/</guid><description/></item><item><title>A New Method of {MHP} Analysis for Languages with Dynamic Barriers</title><link>https://sbjoshi.github.io/publication/mhp-ipdpsw12/</link><pubDate>Thu, 01 Mar 2012 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/mhp-ipdpsw12/</guid><description/></item><item><title>Underspecified harnesses and interleaved bugs</title><link>https://sbjoshi.github.io/publication/underspecified-popl12/</link><pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/underspecified-popl12/</guid><description/></item><item><title>Distributed Generalized Dynamic Barrier Synchronization</title><link>https://sbjoshi.github.io/publication/icdcn11/</link><pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/icdcn11/</guid><description/></item><item><title>Reactivity in SystemC Transaction-Level Models</title><link>https://sbjoshi.github.io/publication/hvc07/</link><pubDate>Mon, 01 Oct 2007 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/publication/hvc07/</guid><description/></item><item><title>Posts</title><link>https://sbjoshi.github.io/post/pinaka-usermanual/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sbjoshi.github.io/post/pinaka-usermanual/</guid><description>&lt;h1 id="how-to-use-pinaka">How to use Pinaka&lt;/h1>
&lt;p>Pinaka is a single-path symbolic execution engine, built on top of
&lt;a href="https://www.cprover.org" target="_blank" rel="noopener">CPROVER&lt;/a> framework.&lt;/p>
&lt;p>In the following text, we will show how to use Pinaka through various examples.&lt;/p>
&lt;h2 id="using-assert-to-check-properties">Using &lt;code>assert&lt;/code> to check properties&lt;/h2>
&lt;p>Pinaka verifies a program with respect to given specifications. These specifications are typically given as a set of program assertions using &lt;code>assert&lt;/code> statements in the program.&lt;/p>
&lt;pre>&lt;code class="language-c">1 #include &amp;lt;assert.h&amp;gt;
2 int main()
3 {
4 int a, b=5;
5 int c = a+b;
6 assert(c&amp;lt;100);
7 return 0;
8 }
&lt;/code>&lt;/pre>
&lt;p>Look at the example shown above. The C language standard does not
forbid the use of uninitialized variable, however, using uninitialized variables may lead to undefined behavior. Here, &lt;code>a&lt;/code> is uninitialized and therefore, as per the C language standard, it is free to to take any value within the domain of &lt;code>int&lt;/code>.&lt;/p>
&lt;p>As, you can observe, on &lt;code>line 6&lt;/code>, assertion has been given. Programmers or user of Pinaka is supposed to use &lt;code>assert&lt;/code> to indicate what properties they want Pinaka to verify the program against.&lt;/p>
&lt;p>On the above program, the following command shall be issued:&lt;/p>
&lt;p>&lt;code>pinaka filename.c&lt;/code>&lt;/p>
&lt;p>Pinaka will show the following output:&lt;/p>
&lt;pre>&lt;code>Running with 8 object bits, 56 offset bits (default)
Parsing /tmp/try4.c
&amp;lt;command-line&amp;gt;: warning: &amp;quot;__STDC_VERSION__&amp;quot; redefined
&amp;lt;built-in&amp;gt;: note: this is the location of the previous definition
Converting
Type-checking try4
Generating GOTO Program
Adding CPROVER library (x86_64)
Generic Property Instrumentation
Removal of function pointers and virtual functions
Depth First Search
Full Incremental Mode
OUR FUNCTION CALLED
Number of dropped states: 0
Generated 1 VCC(s), 1 remaining after simplification
Number of SAT queries made: 0
Number of new SAT instances: 0
Number of total paths: 0
Number of feasible path: 1
Number of infeasible path: 0
Runtime: 0.036s total, 0.001s SAT
[main.assertion.1] assertion c&amp;lt;100: FAILED
** 1 of 1 failed
VERIFICATION FAILED (ReachSafety)
&lt;/code>&lt;/pre>
&lt;p>Note that without any assertions, Pinaka does not have any specification to verify the program. Therefore the following program would result in &lt;code>VERIFICATION SUCCESSFULL&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-c">
1 #include &amp;lt;assert.h&amp;gt;
2 int main()
3 {
4 int a, b=5;
5 int c = a+b;
6 return 0;
7 }
&lt;/code>&lt;/pre>
&lt;p>&lt;code>printf&lt;/code> statements are irrelevant for Pinaka as it does not consider any &lt;code>printf&lt;/code> as part of the specification.&lt;/p>
&lt;h2 id="verifying-functions-other-than-main-and-signed-integer-overflow-check">Verifying functions other than &lt;code>main&lt;/code> and signed integer overflow check&lt;/h2>
&lt;p>By default, Pinaka assumes that the entry point, or starting point for analysis would be &lt;code>main&lt;/code> subroutine. However, one can specify a subroutine other than &lt;code>main&lt;/code> as well and verify the subroutine.&lt;/p>
&lt;p>For example,&lt;/p>
&lt;pre>&lt;code class="language-c">int inc(int x)
{
return ++x;
}
&lt;/code>&lt;/pre>
&lt;p>Let us assume that we want to check for signed integer overflow for &lt;code>inc&lt;/code> subroutine. We should use the following command&lt;/p>
&lt;p>&lt;code>pinaka --signed-overflow-check --function inc filename.c&lt;/code>&lt;/p>
&lt;p>Note, that we combined two command line options here.&lt;/p>
&lt;ol>
&lt;li>&lt;code>--signed-overflow-check&lt;/code> tells Pinaka to use signed integer arithmetic overflow as the property to be verified. In such a case, we do not have to provide any &lt;code>assert&lt;/code> statements in the program.&lt;/li>
&lt;li>&lt;code>--function inc&lt;/code> tells Pinaka to use subroutine &lt;code>inc&lt;/code> as the starting point for the analysis. In this case, the source file need not have a &lt;code>main&lt;/code> subroutine inside it. Even if it is present, it will be &lt;em>ignored&lt;/em> .&lt;/li>
&lt;/ol>
&lt;h2 id="array-index-out-of-bounds-check-and-showing-the-trace">Array index out-of-bounds check and showing the trace&lt;/h2>
&lt;p>Pinaka supports array index out-of-bounds check as in-built property.&lt;/p>
&lt;p>For example,&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
int main()
{
int a[] = {0,1,2,3,4};
int i,sum=0;
for (i=0;i&amp;lt;=5;i++)
{
sum+=a[i];
assert(sum&amp;gt;=0);
}
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>Let us first try without the array index out-of-bounds check.&lt;/p>
&lt;p>&lt;code>pinaka filename.c&lt;/code>&lt;/p>
&lt;p>The result would be &lt;code>VERIFICATION FAILED&lt;/code> because the &lt;code>sum&lt;/code> can indeed become negative since &lt;code>a[5]&lt;/code> can be &lt;code>-11&lt;/code> or less. Note that the above program would compile successfully.&lt;/p>
&lt;p>If we also want to see the trace/potential execution through which the program would fail we should issue the following command:&lt;/p>
&lt;p>&lt;code>pinaka --show-trace filename.c&lt;/code>&lt;/p>
&lt;p>The trace would clearly show that the value for &lt;code>a[5]&lt;/code> would be so much negative so that &lt;code>sum&lt;/code> becomes negative. We can observe that this issue arises as the program tries to access an array index which is outside the legal range of the array.&lt;/p>
&lt;p>To perform the array index out-of-bounds check, the following command shall be issued:&lt;/p>
&lt;p>&lt;code>pinaka --bounds-check --show-trace filename.c&lt;/code>&lt;/p>
&lt;p>Now it will show that the upper bound on array index &lt;code>a&lt;/code> is violated.&lt;/p>
&lt;h2 id="pinaka-search-modes">Pinaka search modes&lt;/h2>
&lt;p>Pinaka supports various internal modes, each with having their own advantages and disadvantages in terms of speed and memory consumption.&lt;/p>
&lt;p>For the search, two modes are supported, Since, Pinaka is a single path symbolic execution engine, the default mode of the search is &lt;em>depth-first search&lt;/em>. If you wish to use &lt;em>breadth-first search&lt;/em> instead, please use the following command.&lt;/p>
&lt;p>&lt;code>pinaka --bfs filename.c&lt;/code>&lt;/p>
&lt;p>Similarly, the default incremental mode of Pinaka is &lt;em>full incremental mode&lt;/em>. If, you wish to use &lt;em>partial incremental mode&lt;/em>, please use the following command.&lt;/p>
&lt;p>&lt;code>pinaka --partial-incremental filename.c&lt;/code>&lt;/p>
&lt;p>Note that we &lt;strong>DO NOT&lt;/strong> recommend to use &lt;em>partial incremental mode&lt;/em> with &lt;em>breadth-first search&lt;/em> as it can quickly consume a lot of memory.&lt;/p>
&lt;p>For SVCOMP, we found &lt;em>partial incremental mode&lt;/em> with the &lt;em>deapth-first search&lt;/em> to be the best combination to use. So the command to use this combination would be&lt;/p>
&lt;p>&lt;code>pinaka --partial-incremental filename.c&lt;/code>&lt;/p>
&lt;h2 id="bit-width-options">Bit-width options&lt;/h2>
&lt;p>Pinaka has options to specify the width for a word. For example, you can choose if the width of a word is 16-bit, 32-bit or 64 bit. Pinaka internally uses a technique called &lt;em>bit-blasting&lt;/em> to provide a bit-precise analysis of the program. For example, the specified bit-width would determine when to flag for an overflow, underflow for integers.&lt;/p>
&lt;p>These options can be used as follows:&lt;/p>
&lt;p>&lt;code>pinaka --64 filename.c&lt;/code>&lt;/p>
&lt;p>Similarly, to specify bit-width of 16 or 32 bits, one can use &lt;code>--16&lt;/code> or &lt;code>--32&lt;/code> respectively.&lt;/p>
&lt;h2 id="floating-point-rounding-modes">Floating-point rounding modes&lt;/h2>
&lt;p>Pinaka supports four rounding modes for floating-point arithmetic. Floating-point modelling is compliant to IEEE 754 standard.&lt;/p>
&lt;p>There are four rounding modes:&lt;/p>
&lt;ul>
&lt;li>Round to nearest (&lt;code>--round-to-nearest&lt;/code>)&lt;/li>
&lt;li>Round to $+\infty$ (&lt;code>--round-to-plus-inf&lt;/code>)&lt;/li>
&lt;li>Round to $-\infty$ (&lt;code>--round-to-minus-inf&lt;/code>)&lt;/li>
&lt;li>Round to $0$ (&lt;code>--round-to-zero&lt;/code>)&lt;/li>
&lt;/ul>
&lt;p>One can refer to this &lt;a href="https://en.wikipedia.org/wiki/Floating-point_arithmetic" target="_blank" rel="noopener">Wikipedia article&lt;/a> to know more about rounding modes.&lt;/p>
&lt;h2 id="divide-by-zero-check">Divide by zero check&lt;/h2>
&lt;p>You can use &lt;code>--div-by-zero-check&lt;/code> to tell Pinaka to detect potential division by zero.&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
int main()
{
int a,b;
int c = a/b;
assert(c&amp;gt;0);
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>Look at the example above. There is a potential division by $0$ since &lt;code>b&lt;/code> being an uninitialized variable, can potentially have the value of &lt;code>0&lt;/code>.&lt;/p>
&lt;p>You can use the following command to tell Pinaka to check for such errors as follows:&lt;/p>
&lt;p>&lt;code>pinaka --div-by-zero-check filename.c&lt;/code>&lt;/p>
&lt;p>Note that, the assertion &lt;code>assert(c&amp;gt;0)&lt;/code> will be shown as &lt;code>OK&lt;/code> if the division by zero check is enabled. Because the assertion is after the division by zero error. The program is in an undefined state after the error, therefore, this result of &lt;code>OK&lt;/code> should be ignored as Pinaka will already show that there is a division by zero error in the expression &lt;code>int c=a/b&lt;/code>.&lt;/p>
&lt;p>If you omit the flag for this check, it will correctly raise a warning for assertion violation.&lt;/p>
&lt;p>&lt;code>pinaka filename.c&lt;/code>&lt;/p>
&lt;p>On the above program, this will correctly raise a warning of assertion &lt;code>assert(c&amp;gt;0)&lt;/code> being violated.&lt;/p>
&lt;p>Note that along the same path, if there are multiple properties, Pinaka will correctly identify the status of the first property and ignore the rest, therefore, reporting the status of &lt;code>OK&lt;/code> for other properties.&lt;/p>
&lt;p>For example,&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
int main()
{
int a,b;
int c = a/b;
int d = c/a;
assert(c&amp;gt;0);
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>for the above program, when you use &lt;code>--div-by-zero-check&lt;/code> it will show error only on &lt;code>int c=a/b&lt;/code> and the rest will be ignored or shown as &lt;code>OK&lt;/code>.&lt;/p>
&lt;h2 id="pointer-checks">Pointer checks&lt;/h2>
&lt;p>Pinaka supports certain checks with respect to pointers. All of the checks mentioned below are done when you provide &lt;code>--pointer-check&lt;/code> flag to Pinaka.&lt;/p>
&lt;h3 id="null-pointer-check">Null-pointer check&lt;/h3>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
#define NULL 0
int max (int *p, int *q)
{
int tmp1=*p;
int tmp2=*q;
if (tmp1 &amp;gt; tmp2) return tmp1;
else return tmp2;
}
int main()
{
int *a=NULL;
int b=5;
int *c = &amp;amp;b;
max(a,c);
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>Use the following command to run pointer-checks:&lt;/p>
&lt;p>&lt;code>pinaka --pointer-check filename.c&lt;/code>&lt;/p>
&lt;p>It performs checks like NULL pointer dereference, invalid pointer usage, pointer use after deallocation of memory, pointer access outside the bounds, dangling pointer.&lt;/p>
&lt;h3 id="use-after-free-check">Use-after-free check&lt;/h3>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
#define NULL 0
int max (int *p, int *q)
{
int tmp1=*p;
int tmp2=*q;
if (tmp1 &amp;gt; tmp2) return tmp1;
else return tmp2;
}
int main()
{
int *a=NULL;
int b=5;
int *c = &amp;amp;b;
// max(a,c);
a=malloc(10*sizeof(int));
*a=10;
free(a);
*a=5;
return 0;
}
&lt;/code>&lt;/pre>
&lt;h3 id="dangling-pointer-check-example">Dangling pointer check example&lt;/h3>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
#define NULL 0
int a;
int *q=&amp;amp;a;
void foo ()
{
int x;
q=&amp;amp;x;
}
int main()
{
int *a=NULL;
int b=5;
int *c = &amp;amp;b;
foo();
b = *q;
return 0;
}
&lt;/code>&lt;/pre>
&lt;h3 id="outside-dynamic-object-bounds-check">Outside dynamic object bounds check&lt;/h3>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
#define NULL 0
int a;
int *q=&amp;amp;a;
void foo ()
{
int x;
q=&amp;amp;x;
}
int main()
{
int *a=NULL;
int b=5;
int *c = &amp;amp;b;
q=malloc(4*sizeof(int));
*(q+5)=5;
return 0;
}
&lt;/code>&lt;/pre>
&lt;h3 id="outside-object-bounds">Outside object bounds&lt;/h3>
&lt;pre>&lt;code class="language-c">#include &amp;lt;assert.h&amp;gt;
#define NULL 0
int a;
int *q=&amp;amp;a;
void foo ()
{
int x;
q=&amp;amp;x;
}
int main()
{
int *a=NULL;
int b=5;
int *c = &amp;amp;b;
int d[] = {1,2,3,4};
q=d;
*(q+10)=10;
return 0;
}
&lt;/code>&lt;/pre>
&lt;h2 id="memory-leak-detection">Memory leak detection&lt;/h2>
&lt;p>Pinaka can check for memory leaks (allocated memory not freed during the lifetime of the program). Provide &lt;code>--memory-leak-check&lt;/code> flag to perform such a check.&lt;/p>
&lt;pre>&lt;code class="language-c">include &amp;lt;assert.h&amp;gt;
#define NULL 0
int a;
int *q=&amp;amp;a;
void foo ()
{
int x;
q=&amp;amp;x;
}
int main()
{
int *a=NULL;
int b=5;
int *c = &amp;amp;b;
int d[] = {1,2,3,4};
q=malloc(4*sizeof(10));
*q=5;
q=d;
*(q+1)=10;
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>Use the command&lt;/p>
&lt;p>&lt;code>pinaka --memory-leak-check filename.c&lt;/code>&lt;/p>
&lt;h2 id="note">Note&lt;/h2>
&lt;p>Please note that Pinaka being a single-path symbolic-execution engine with early pruning will return as soon as the first violation of the given property is encountered. All the other properties will remain un-checked, and therefore, the status of the other properties, even if shown &lt;code>OK&lt;/code> does not indicate that these properties hold.&lt;/p>
&lt;h2 id="termination-check">Termination check&lt;/h2>
&lt;p>Pinaka unrolls any loop/recursion on-the-fly and therefore, the termination of the program can be checked by virtue of termination of execution of Pinaka itself. If Pinaka returns &lt;code>VERIFICATION SUCCESSFUL&lt;/code> it also implies that the program terminates.&lt;/p>
&lt;p>If the program is non-terminating (infinite loop or recursion), Pinaka will return if on some path there is a property violation, it will not terminate otherwise.&lt;/p></description></item></channel></rss>