[{"authors":["admin"],"categories":null,"content":"I am an Assistant Professor with the Department of CSE at IIT Hyderabad.\n","date":1609459200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1609459200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://sbjoshi.github.io/starter-academic/author/saurabh-joshi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/starter-academic/author/saurabh-joshi/","section":"authors","summary":"I am an Assistant Professor with the Department of CSE at IIT Hyderabad.","tags":null,"title":"Saurabh Joshi","type":"authors"},{"authors":["Saurabh Joshi","Gautam Muduganti"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"dc2e8f39e9f55297c3c27b52b379ea34","permalink":"https://sbjoshi.github.io/starter-academic/publication/gpurepair-vmcai21/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/starter-academic/publication/gpurepair-vmcai21/","section":"publication","summary":"This paper presents a tool and a technique to fix data-race and barrier divergence errors in CUDA and OpenCL programs.","tags":["Formal Verification"],"title":"GPURepair: Automated Repair of GPU Kernels","type":"publication"},{"authors":["Utpal Bora","Santanu Das","Pankaj Kukreja","Saurabh Joshi","Ramakrishna Upadrasta","Sanjay V Rajopadhye"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"a5eb136eb2a737801309f2bcaa640c8f","permalink":"https://sbjoshi.github.io/starter-academic/publication/llov-taco20/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/llov-taco20/","section":"publication","summary":"This paper presents a tool, LLOV, which leverages polyhedral compilation for fast data-race checking for OpenMP Programs.","tags":["Program Analysis"],"title":"LLOV: A Fast Static Data-Race Checker for OpenMP Programs","type":"publication"},{"authors":["Sriram Bhyravarapu","Saurabh Joshi","Subrahmanyam Kalyanasundaram","Anjeneya Swami Kare"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"b637f3ac96c5cfa9045e75d7afc90288","permalink":"https://sbjoshi.github.io/starter-academic/publication/kicoloring/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/starter-academic/publication/kicoloring/","section":"publication","summary":"This paper is primarily about NP-completeness of $(k,i)$-coloring of graph and giving a parameterized algorithm for this problem using feedback vertex set as the parameter.","tags":["CS Theory"],"title":"On the tractability of $(k,i)$-coloring (Extended Journal Version)","type":"publication"},{"authors":["Ruben Martins","Saurabh Joshi","Vasco Manquinho","Ines Lynce"],"categories":null,"content":"","date":1570665600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570665600,"objectID":"e80504c14e255fa6b19c68668d69c382","permalink":"https://sbjoshi.github.io/starter-academic/publication/reflections-virtualvolume-cp19/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/reflections-virtualvolume-cp19/","section":"publication","summary":"To celebrate the first 25 years of the International Conference on Principles and Practice of Constraint Programming (CP) the editors invited the authors of the most cited paper of each year to write a commentary on their paper. This report describes our reflections on the CP 2014 paper \"Incremental Cardinality Constraints for MaxSAT\" and its impact on the Maximum Satisfiability community and beyond.","tags":["Constraint Programming"],"title":"Reflections on \"Incremental Cardinality Constraints for MaxSAT\"","type":"publication"},{"authors":["Saurabh Joshi","Prateek Kumar","Sukrut Rao","Ruben Martins"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"dd6170840c6d44399fe22285c7d8c920","permalink":"https://sbjoshi.github.io/starter-academic/publication/open-wbo-inc-jsat/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/starter-academic/publication/open-wbo-inc-jsat/","section":"publication","summary":"This paper presents a couple of incomplete Weighted MaxSAT solving techniques along with analysis on the deviation to the optimal value.","tags":["Constraint Programming"],"title":"Open-WBO-Inc: Approximation Strategies for Incomplete Weighted MaxSAT","type":"publication"},{"authors":["Yash Pote","Saurabh Joshi","Kuldeep Meel"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"abbd28be6439d61e161fd2ce2e2ebd76","permalink":"https://sbjoshi.github.io/starter-academic/publication/phasetransition-ijcai19/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/starter-academic/publication/phasetransition-ijcai19/","section":"publication","summary":"This paper studies phase transition behaviour of CARD-XOR formulas.","tags":["Constraint Programming"],"title":"Phase Transition Behavior of Cardinality and XOR Constraints","type":"publication"},{"authors":["Eti Chaudhary","Saurabh Joshi"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"f5e270bffa4c0c701f270e78c3e6dca5","permalink":"https://sbjoshi.github.io/starter-academic/publication/pinaka-tacas19/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/starter-academic/publication/pinaka-tacas19/","section":"publication","summary":"This paper describes, Pinaka, a symbolic execution engine that leverages incremental SAT solving.","tags":["Formal Verification"],"title":"Pinaka: Symbolic Execution Meets Incremental Solving - (Competition Contribution)","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c3decd8ed8d3b9761c9b404b98874540","permalink":"https://sbjoshi.github.io/starter-academic/project/llov/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/starter-academic/project/llov/","section":"project","summary":"A static data-race checker for OpenMP programs.","tags":["Program Analysis"],"title":"LLOV","type":"project"},{"authors":["Saurabh Joshi","Prateek Kumar","Ruben Martins","Sukrut Rao"],"categories":null,"content":"","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"19d838cff7fe52274041c7cd4ba305e7","permalink":"https://sbjoshi.github.io/starter-academic/publication/open-wbo-inc-cp18/","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/starter-academic/publication/open-wbo-inc-cp18/","section":"publication","summary":"This paper presents a couple of incomplete Weighted MaxSAT solving techniques that allowed _Open-WBO-Inc_ to win accolades in MaxSAT evaluations 2018 and MaxSAT evaluations 2019.","tags":["Constraint Programming"],"title":"Approximation Strategies for Incomplete MaxSAT","type":"publication"},{"authors":null,"categories":null,"content":"Open-WBO-Inc Open-WBO-Inc is an open-source incomplete solver for MaxSAT. Often, real-world applications demand a good answer to MaxSAT optimization problem very quickly. Incomplete solvers strive to find a good answer very fast but may not guarantee optimality of the provided answer.\nOpen-WBO-Inc has won several accolades at international arena. In addition, it serves as a platform on top of which other award winning solvers such as Loandra and TT-Open-WBO-Inc has been built.\n MaxSAT Evaluation 2019: 2 Bronze MaxSAT Evaluation 2018: 1 Gold, 1 Silver  ","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"bfbf4b0122299a81eadbe909e628f0e8","permalink":"https://sbjoshi.github.io/starter-academic/project/openwboinc/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/starter-academic/project/openwboinc/","section":"project","summary":"An open-source solver for incomplete MaxSAT","tags":["Constraint Programming"],"title":"Open-WBO-Inc","type":"project"},{"authors":["Saurabh Joshi","Subrahmanyam Kalyanasundaram","Anjeneya Swami Kare","B Sriram"],"categories":null,"content":"","date":1517443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517443200,"objectID":"e899c492ef188edc77e305fb3c8ec315","permalink":"https://sbjoshi.github.io/starter-academic/publication/kicoloring-caldam18/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/starter-academic/publication/kicoloring-caldam18/","section":"publication","summary":"This paper is primarily provides a parameterized algorithm for $(k,i)$-coloring  problem using feedback vertex set as the parameter.","tags":["CS Theory"],"title":"On the tractability of $(k,i)$-coloring","type":"publication"},{"authors":null,"categories":null,"content":"GPURepair GPURepair is a tool that can propose a fix to data-race and barrier-divergence errors in CUDA and OpenCL kernels. It uses GPUVerify as an oracle. It can also propose a fix for inter-block data-race in CUDA kernels using CUDA Cooperative Groups.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"ac2f2e8f7bdb1cbbe5c87d82b058fdc2","permalink":"https://sbjoshi.github.io/starter-academic/project/gpurepair/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/starter-academic/project/gpurepair/","section":"project","summary":"A tool for automated repair of CUDA and OpenCL kernels","tags":["Formal Verification","Automated Program Repair"],"title":"GPURepair","type":"project"},{"authors":null,"categories":null,"content":"OpenWBO OpenWBO is a modular open-source sover for MaxSAT and Pseudo-Boolean formulas. OpenWBO has won several accolades in various international arena.\n MaxSAT Evaluation 2017: 2 Gold, 1 Silver MaxSAT Evaluation 2016: 1 Gold, 1 Silver Pseudo-Boolean Evaluation 2016: 2 Silver, 2 Bronze MaxSAT Evaluation 2015 : 1 Gold, 1 Silver MaxSAT FLoC Olympic Games 2014 : 2 Gold MaxSAT Evaluation 2014 : 1 Gold, 1 Silver  ","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"b3c7ef6ee43ad1c9dfb37a5144110647","permalink":"https://sbjoshi.github.io/starter-academic/project/openwbo/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/starter-academic/project/openwbo/","section":"project","summary":"An open-source MaxSAT and Pseudo-Boolean solver","tags":["Constraint Programming"],"title":"OpenWBO","type":"project"},{"authors":null,"categories":null,"content":"Pinaka: Symbolic Execution meets Incremental Solving Symbolic execution as well as incremental solving has been quite well known concepts to the researchers and students working in the field of Formal Methods.\nToday I am going to write about Pinaka, a symbolic execution engine that combines symbolic execution with incremental solving in a fairly simple fashion.\nIncremental Solving Many modern day constraint solvers, such as SAT and SMT solvers support incremental solving in some fashion. Say, for some problem, we require solutions for the following set of formulas: $\\varphi, \\varphi \\wedge \\Delta_1, \\varphi \\wedge \\Delta_1 \\wedge \\Delta_2$\nOne of the ways to solve these is to create a solver instance for each of these formulas separately and ask the solver for a solution for each of these separately. Note however, that any assignment/model/interpretation that does not satisfy $\\varphi$ is not going to satisfy the other two. Similarly, any assignment that does not satisfy $\\varphi\\wedge\\Delta_1$ is not going to satisfy the last formula. Essentially, adding more constraints to the existing formula is going to preserve the fact that assignments that falsifies a formula continue to do so even after more constraints are added.\nIt would result in a huge performance gain, if we use the same solver instance to solve all the three formulas. When we reuse the solver instance, the internal state of the solver including variable and clause activity scores, learned clauses, etc., are carried over and reused for the next query.\nThis way of solving a set of formulas with successive queries to the same solver will be denoted as partial incremental mode.\nNow, suppose we have the following set of formulas: $\\varphi \\wedge \\Delta_1, \\varphi \\wedge \\Delta_2, \\varphi \\wedge \\Delta_3$. Note that, though $\\varphi$ remains common, it is no longer the case that one formula is just addition of constraints over the other. The second formula can be obtained from the first by deleting $\\Delta_1$ and adding $\\Delta_2$. However, the moment you delete a set of constraints, the assignment that used to falsify the old formula may no longer falsify the new formula. Therefore, the search space that was discarded earlier by the solver has to be explored again. The internal state of the solver can not easily be reused in such a scenario.\nHowever, many modern day solvers have another trick up their sleeve, called assumptions. Assumptions are a list of literals that can be logically thought of as added unit clauses. When you know that some constraint may no longer be required for successive queries, you can add that constraint being enforced by an assumption. Therefore, the first formula, can be rewritten as $\\varphi \\wedge (b_1 \\implies \\Delta_1) \\wedge [b_1]$. Here, $[b_1]$ is an assumption, which can logically be thought as a unit clause. Therefore, making this formula equisatisfiable to $\\varphi \\wedge \\Delta_1$. To transform, the first formula to the second one, now we can add $(b_2\\implies \\Delta_2)$ and change the set of assumptions to $[\\neg b_1,b_2]$. So the second formula now looks like:\n$$\\varphi \\wedge (b_1\\implies \\Delta_1) \\wedge (b2\\implies \\Delta_2) \\wedge [\\neg b_1,b_2]$$.\nWhen you think that assumptions are logically just unit clauses, then the above formula in some sense deletes $\\Delta_1$ because the premise of the implicant is false. Therefore, we are transforming one formula to the next just by adding $(b_i \\implies \\Delta_i)$ and changing assumptions. Note that we are changing $[b_1]$ to $[\\neg b_1]$, which looks like we are deleting $b_1$ and adding $\\neg b_1$, but solvers treat assumptions in a spacial manner internally. It is still the case that the assignment that falsifies the first formula may no longer falsify the second formula. However, using assumptions still allow a lot of information pertaining to $\\varphi$ to be carried over to the next query. Thus, assumptions allow us to salvage at least some information, which would be lost if we were to create a different solver instance for each query.\nOf course, adding such $(b_i \\implies \\Delta_i)$ for a lot of successive queries result in degradation of performance because of large memory footprint and slower iteration over internal data-structures. However, assumptions allows us to reuse a solver instance and can give great performance benefits if the common subformula $\\varphi$ is very large and $\\Delta_i$ are small and few in numbers.\nThis way of using the same solver instance for successive queries will be denoted as full incremental mode.\nSymbolic Execution Let\u0026rsquo;s take a look at a motivating example for symbolic execution.\nLook at the subroutine foo given below. Note that the assertion violation will happen only when variable y gets -10 as its value at line 1. Assuming an int to be of 32 bits, and if you were to test this subroutine by generating values of y uniformly randomly and running foo, then the probability of you finding the bug will be $2^{-32}$.\n1 void foo(int y) { 2 int x=10; 3 x=x+y; 4 if(x==0) { 5 x=x+1; 6 if(y\u0026lt;-10) 7 x=x-1; 8 } 9 else { 10 x=0; 11 } 12 assert(x==0); 13 }  The problem with testing, as mentioned above, is that a single run only exposes program behaviour for a single input value along a single path.\nIn symbolic execution, it is possible to explore program behaviour for a set of input values along a single path. We will not talk about multi-path symbolic execution in this post.\nSymbolic execution uses a predicate at every program point along a path to represent the set of values program variables can take along the given path. This predicate is also often called a symbolic state.\nFor example, the symbolic state after executing lines 1-3 would be :\n$$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0 \\quad (1) $$\nHere, $x_0,x_1,y_0$ are symbolic /mathematical variables that represent the set of values that the corresponding program variable can take at corresponding program points. For example, $(x_0,10), (x_1,11),(y_0,3)$ as a program state is not possible after executing line 3 as it does not satisfy the predicate mentioned above. On the other hand $(x_0,10),(x_1,12),(y_0,2)$ satisfies the predicate, indicating that after executing lines 1-3 program variable x can be 12 and y can be 2. Similarly, $(x_0,10),(x_1,0),(y_0,-10)$ is also a solution to the predicate indicating that x taking the value 0 and y taking the value -10 at line 4 is a possibility.\nLine 4 is a branch and gives rise to two symbolic states. Symbolic state for the then branch is: $$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0\\wedge x_1=0\\quad(2)$$\nThe symbolic state for the else branch is: $$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0\\wedge x_1\\neq0\\quad(3)$$.\nPinaka being a single path execution engine, maintains a worklist of symbolic states that are yet to be explored further. Therefore, at a branch, it picks one state to be explored further and puts the other one on the worklist. Say, it picked the symbolic state for the then branch. Pinaka also employs eager feasibility checks. In other words, at every branch, it poses a query to a constraint solver whether the symbolic state is feasible or not. If there is no solution to the predicate, then the corresponding symbolic state is deemed to be infeasible, indicating that in an actual/concrete execution, it is not possible for the control to reach this point.\nIn our example, then branch at line 4 is feasible. Symbolic state for the then branch at line 6would be:\n$$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0\\wedge x_1=0 \\ \\wedge x_2=x_1+1 \\wedge y_0\u0026lt;-10 \\quad(4) $$\nSymblic state for (implicit) else at line 8 would be: $$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0\\wedge x_1=0 \\ \\wedge x_2=x_1+1 \\wedge y_0\\geq -10 \\quad(5) $$\nPinaka uses incremental solving aggressively. Note that the symbolic state for then branch at line 4 is of the form $\\varphi$ and the symbolic state for the then branch at line 6 differs by two additional constraint $x_2=x_1+1 \\wedge y_0\u0026lt;-10$ which can be considered as $\\Delta_1$ as mentioned in earlier section. Therefore, along a single path, Pinaka continues to reuse the same solver instance as long as the symbolic state remains feasible.\nObserve that this symbolic state given in $(4)$ above is infeasible and therefore, in a real execution line 7 is unreachable irrespective of the input value of y.\nIn the DFS (depth first search) exploration strategy, Pinaka picks the last unexplored symbolic state from the list. This can easily be achieved when we operate the worklist of symbolic states pending further exploration in a LIFO (Last In First Out) manner. In this example, it would pick the symbolic state mentioned at (5) above, corresponding to the if condition being false at line 6.\nIn the partial-incremental mode, once a symbolic state is found to be infeasible, a new solver instance is created to explore the yet unexplored symbolic state, in this case, (5) above.\nIn the full incremental mode, the predicate/formula at line 6 would have looked like the following: $$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0 \\ \\wedge (b_1 \\implies x_1=0) \\wedge (b_1 \\implies x_2=x_1+1) \\ \\wedge (b_1 \\implies (b_2 \\implies y_0\u0026lt;-10)) \\wedge [b_1,b_2] \\quad(6) $$\nNotice that a new assumption is added for every branch condition as later we may want to backtrack from a then branch and explore an else branch. So in the full incremental mode, the same solver instance will be reused after the symbolic state at line 6 for the then branch is found to be infeasible. For the else branch, the formula would look like the following: $$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0 \\ \\wedge (b_1 \\implies x_1=0) \\wedge (b_1 \\implies x_2=x_1+1) \\ \\wedge (b_1 \\implies (b_2 \\implies y_0\u0026lt;-10)) \\\n\\wedge (b_1 \\implies (\\neg b_2 \\implies y\\geq -10)) \\wedge [b_1,\\neg b_2] \\quad(7) $$\nOnce the symbolic execution has gone through the path depicted by lines 1-6, 8,11 we have to check for assertion violation. Essentially, we again want to know, if there is any set of values that program variables can take that can result in assertion violation. This can be done by asking if the following symbolic state is feasible:\n$$y_0 \\wedge x_0 = 10 \\wedge x_1 = x_0 + y_0\\wedge x_1=0 \\ \\wedge x_2=x_1+1 \\wedge y_0\\geq -10 \\wedge x_2\\neq 0 \\quad(8) $$\nObserve that we negated the condition inside the assertion as we want to know if the program variables can take a set of values that violates (negates) the condition given in the assertion. Note that (8) above is satisfiable with $(y_0,-10)$, thus revealing that foo can fail if the value of the parameter y is -10.\nNumber of paths in a program can grow exponentially in proportion to the number of branches in the program. This path explosion problem can pose quite a problem for single-path symbolic execution engines such as Pinaka. Eager infeasibility checks employed by Pinaka gives it tremendous performance boost as all the paths beyond an infeasible symbolic state is discarded. However, doing eager infeasibility checks would mean that every time a branch is encountered, a solver query has to be fired. Since querying a solver is expensive, increasing the number of queries can pose another challenge. That is when integration of incremental solving can provide tremendous benefit.\nTermination Loops and recursions are primary programming constructs in a programming language that causes non-termination in a program.\nPinaka performs loop-unrolling and function in-lining lazily and on-demand. This feature allows it to be used to check for termination in some cases.\nLet\u0026rsquo;s take a look at the following program fragment:\n1 while(x \u0026lt; 10) { 2 y = y + 1; 3 if(y \u0026lt; 5) { 4 x = x + 1 5 } 6 }  Note that for all the values of x and y, if they satisfy $x-y\u0026gt;5 \\vee x\\geq 10$, this loop will terminate. It may not terminate otherwise. However, Pinaka does not compute this relation. Instead, it treats the loop condition just as a branch. So the loop will keep being unrolled on-demand as long as the symbolic state at line 1 continues to remain feasible. In another words, if there is any set of values for x and y which would make it possible for the loop to iterate at least one more time, Pinaka will also go around the loop symbolically executing the loop at least one more time. As a consequence, for a program which does not violate any assertions (safe programs), Pinaka will terminate only if the program itself is terminating. Of course, we are assuming that the solver queries themselves terminate and Pinaka does not run out of memory and time.\nFor programs, that may violate assertions, this guarantee does not hold. Since if Pinaka finds an assertion violation along some path, it will terminate even if there exist paths in the programs which are non-terminating.\nDo it yourself Those who want to try this example out and compare testing against symbolic execution, following is the C++ program for testing:\n#include\u0026lt;random\u0026gt; #include\u0026lt;limits\u0026gt; #include\u0026lt;iostream\u0026gt; #include\u0026lt;cassert\u0026gt; void foo(int y) { int x=10; x=x+y; if(x==0) { x=x+1; if(y\u0026lt;-10) x=x-1; } else { x=0; } assert(x==0); } int main() { std::random_device rseed; std::mt19937 rng(rseed()); std::uniform_int_distribution\u0026lt;int\u0026gt; dist(std::numeric_limits\u0026lt;int\u0026gt;::min(),std::numeric_limits\u0026lt;int\u0026gt;::max()); unsigned i=0; unsigned max=1000000; //unsigned max=std::numeric_limits\u0026lt;unsigned\u0026gt;::max(); while(i\u0026lt;max) { std::cout\u0026lt;\u0026lt; \u0026quot;i : \u0026quot; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; foo(dist(rng)); i++; }; return 0; }  Compile, run and observe using the following commands:\n$ g++ -o footest filename.cpp $ ./footest 2\u0026gt;\u0026amp;1 \u0026gt; foorun.log $ tail foorun.log  I could not trigger the assertion violation when I tried. In contrast when you run Pinaka using the following command you will get assertion violation notification in a fraction of a second.\n$ pinaka --function foo filename.c  References  Pinaka binaries are available here. Pinaka performed reasonably well and quite fast in SVCOMP 2019 and SVCOMP 2020 You may also refer to the following paper: Eti Chaudhary and Saurabh Joshi, \u0026ldquo;Pinaka: Symbolic Execution meets Incremental Solving\u0026rdquo;, TOOLympics, TACAS (3), LNCS Vol. 11529, pp. 234\u0026ndash;238, 2019. Pre-print version is available on arXiv.  ","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"efc1767583faf2bd61a84a05cc10030e","permalink":"https://sbjoshi.github.io/starter-academic/project/pinaka/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/starter-academic/project/pinaka/","section":"project","summary":"A symbolic execution engine","tags":["Formal Verification"],"title":"Pinaka","type":"project"},{"authors":["Vojtech Forejt","Saurabh Joshi","Daniel Kroening","Ganesh Narayanaswamy","Subodh Sharma"],"categories":null,"content":"","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"d76365442507dc9925337c09a1b4c994","permalink":"https://sbjoshi.github.io/starter-academic/publication/predictiveanalysis-toplas/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/predictiveanalysis-toplas/","section":"publication","summary":"This paper shows NP-completeness of deadlock detection in certain class of MPI programs. It also presents encoding to analyze a class of MPI programs with respect to deadlocks.","tags":["Formal Verification","Program Analysis"],"title":"Precise Predictive Analysis for Discovering Communication Deadlocks in MPI Programs","type":"publication"},{"authors":["Rajdeep Mukherjee","Saurabh Joshi","Andreas Griesmayer","Daniel Kroening","Tom Melham"],"categories":null,"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"c3ff364d50d810c081446ec3bafce5a6","permalink":"https://sbjoshi.github.io/starter-academic/publication/equivalencefpu-fm16/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/equivalencefpu-fm16/","section":"publication","summary":"This paper describes an efficient technique for equivalence checking of a real-world Floating Point Unit.","tags":["Formal Verification"],"title":"Equivalence Checking of a Floating-Point Unit Against a High-Level C Model","type":"publication"},{"authors":["Ganesh Narayanaswamy","Saurabh Joshi","Daniel Kroening"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"b6a3da14e4e00062ccc1ff64e07cd278","permalink":"https://sbjoshi.github.io/starter-academic/publication/concurrency-ppoppp16/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/concurrency-ppoppp16/","section":"publication","summary":"This paper presents a different encoding that makes Bounded Model Checking faster for concurrent programs.","tags":["Formal Verification","Program Analysis"],"title":"The virtues of conflict: analysing modern concurrency","type":"publication"},{"authors":["Ruben Martins","Saurabh Joshi","Vasco Manquinho","Ines Lynce"],"categories":null,"content":"","date":1446336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446336000,"objectID":"4c86d5a296855bfbb678e53b9700a8c2","permalink":"https://sbjoshi.github.io/starter-academic/publication/inc-cardinality-jsat14/","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/starter-academic/publication/inc-cardinality-jsat14/","section":"publication","summary":"This paper is an extended version of the CP 2014 paper where incremental encoding is extended to weighted MaxSAT.","tags":["Constraint Programming"],"title":"On Using Incremental Encodings in Unsatisfiability-based MaxSAT Solving","type":"publication"},{"authors":["Saurabh Joshi","Ruben Martins","Vasco Manquinho"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"83447e97b4b7488544f55a8909f9d1fa","permalink":"https://sbjoshi.github.io/starter-academic/publication/gte-cp15/","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/starter-academic/publication/gte-cp15/","section":"publication","summary":"This paper describes Generalized Totalizer Encoding (GTE) to encode Pseudo-Boolean Constraints. This encoding led Open-WBO to win accolades in MaxSAT evaluations and Pseudo-Boolean evaluations.","tags":["Constraint Programming"],"title":"Generalized Totalizer Encoding for Pseudo-Boolean Constraints","type":"publication"},{"authors":["Martin Brain","Saurabh Joshi","Daniel Kroening","Peter Schrammel"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"660c846cef8fef1e77f003e565f07790","permalink":"https://sbjoshi.github.io/starter-academic/publication/kiki-sas15/","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/starter-academic/publication/kiki-sas15/","section":"publication","summary":"This paper describes a sound and complete tool, 2LS,  for program verification and the techniques behind its working.","tags":["Formal Verification","Program Analysis"],"title":"Safety Verification and Refutation by $k$-Invariants and $k$-Induction","type":"publication"},{"authors":["Saurabh Joshi","Daniel Kroening"],"categories":null,"content":"","date":1433116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433116800,"objectID":"16689fd18e06244add901b20110c2120","permalink":"https://sbjoshi.github.io/starter-academic/publication/robmc-fm15/","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/starter-academic/publication/robmc-fm15/","section":"publication","summary":"This paper introduces Re-Order Bounded Model Checking to efficiently repair programs on weak memory models.","tags":["Formal Verification","Program Analysis"],"title":"Property-Driven Fence Insertion Using Reorder Bounded Model Checking","type":"publication"},{"authors":["Ruben Martins","Saurabh Joshi","Vasco Manquinho","Ines Lynce"],"categories":null,"content":"","date":1404172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404172800,"objectID":"d17d6bb17264a791308b93632bb7a690","permalink":"https://sbjoshi.github.io/starter-academic/publication/inc-cardinality-cp14/","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/starter-academic/publication/inc-cardinality-cp14/","section":"publication","summary":"This paper describes techniques to incremental encode cardinality constraints. This led Open-WBO to win accolades in MaxSAT evaluations.","tags":["Constraint Programming"],"title":"Incremental Cardinality Constraints for MaxSAT","type":"publication"},{"authors":["Saurabh Joshi","Akash Lal"],"categories":null,"content":"","date":1393632000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1393632000,"objectID":"9fa8ebe152671397de3e5b1e3ac16de9","permalink":"https://sbjoshi.github.io/starter-academic/publication/atomicinf-arxiv/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/atomicinf-arxiv/","section":"publication","summary":"This paper presents a technique for automatically constructing a fix for buggy concurrent programs: given a concurrent program that does not satisfy user-provided assertions, we infer atomic blocks that fix the program. An atomic block protects a piece of code and ensures that it runs without interruption from other threads. Our technique uses a verification tool as a subroutine to find the smallest atomic regions that remove all bugs in a given program. Keeping the atomic regions small allows for maximum concurrency. We have implemented our approach in a tool called AtomicInf. A user of AtomicInf can choose between strong and weak atomicity semantics for the inferred fix. While the former is simpler to find, the latter provides more information about the bugs that got fixed.  We ran AtomicInf on several benchmarks and came up with the smallest and the most precise atomic regions in all of them. We implemented an earlier technique to our setting and observed that AtomicInf is 1.7 times faster on an average as compared to an earlier approach.","tags":["Formal Verification","Automated Program Repair"],"title":"Automatically finding atomic regions for fixing bugs in Concurrent Programs","type":"publication"},{"authors":["Saurabh Joshi","R K Shyamasundar","Sanjeev K Aggarwal"],"categories":null,"content":"","date":1330560000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1330560000,"objectID":"fdfa96c459424c72b406847e192ddb48","permalink":"https://sbjoshi.github.io/starter-academic/publication/mhp-ipdpsw12/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/mhp-ipdpsw12/","section":"publication","summary":"This paper presents a technique to perform May-Happen-in-Parallel analysis for languages with Dynamic Barriers.","tags":["Program Analysis"],"title":"A New Method of {MHP} Analysis for Languages with Dynamic Barriers","type":"publication"},{"authors":["Saurabh Joshi","Shuvendu Lahiri","Akash Lal"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"716fae8dbf22f940a20d1ca6929e30dc","permalink":"https://sbjoshi.github.io/starter-academic/publication/underspecified-popl12/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/underspecified-popl12/","section":"publication","summary":"This paper presents a technique to find interleaved bugs even with incomplete harness.","tags":["Formal Verification","Program Analysis"],"title":"Underspecified harnesses and interleaved bugs","type":"publication"},{"authors":["Shivali Agarwal","Saurabh Joshi","R K Shyamasundar"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"2633ec364a17f683d2f8f8015c416de7","permalink":"https://sbjoshi.github.io/starter-academic/publication/icdcn11/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/starter-academic/publication/icdcn11/","section":"publication","summary":"Static assertion checking of open programs requires setting up a precise harness to capture the environment assumptions. For instance, a library may require a file handle to be properly initialized before it is passed into it. A harness is used to set up or specify the appropriate preconditions before invoking methods from the program. In the absence of a precise harness, even the most precise automated static checkers are bound to report numerous false alarms. This often limits the adoption of static assertion checking in the hands of a user.  In this work, we explore the possibility of automatically filtering away (or prioritizing) warnings that result from imprecision in the harness. We limit our attention to the scenario when one is interested in finding bugs due to concurrency. We define a warning to be an interleaved bug when it manifests on an input for which no sequential interleaving produces a warning. As we argue in the paper, limiting a static analysis to only consider interleaved bugs greatly reduces false positives during static concurrency analysis in the presence of an imprecise harness.  We formalize interleaved bugs as a differential analysis between the original program and its sequential version and provide various techniques for finding them. Our implementation CBugs demonstrates that the scheme of finding interleaved bugs can alleviate the need to construct precise harnesses while checking real-life concurrent programs.","tags":["Program Analysis"],"title":"Distributed Generalized Dynamic Barrier Synchronization","type":"publication"},{"authors":["Frederic Doucet","R K Shyamasundar","Ingolf Krueger","Saurabh Joshi","Rajesh K Gupta"],"categories":null,"content":"","date":1191196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1191196800,"objectID":"2da4877f4cae746c7fce316515f92755","permalink":"https://sbjoshi.github.io/starter-academic/publication/hvc07/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/starter-academic/publication/hvc07/","section":"publication","summary":"SystemC is a popular language used in modeling system-on-chip implementations. To support this task at a high level of abstraction, transaction-level modeling (TLM) libraries have been recently developped. While TLM libraries are useful, it is difficult to capture the reactive nature of certain transactions with the constructs currently available in the SystemC and TLM libraries. In this paper, we propose an approach to specify and verify reactive transactions in SystemC designs. Reactive transactions are different from TLM transactions in the sense that a transaction can be killed or reset. Our approach consists of: (1) a language to describe reactive transactions that can be translated to verification monitors, (2) an architectural pattern to implement reactive transactions, and (3) the verification support to verify that the design does not deadlock, allows only legal behaviors and is always responsive. We illustrate our approach through an example of a transactional memory system where a transaction can be killed or reset before its completion. We identify the architectural patterns for reactive transactions. Our results demonstrate the feasibility of our approach as well as support for a comprehensive verification using RuleBase/NuSMV tools.","tags":["Formal Verification"],"title":"Reactivity in SystemC Transaction-Level Models","type":"publication"}]